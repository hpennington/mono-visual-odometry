{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Odometry pipeline\n",
    "A naive visual odometry implementation with OpenCV (for now), NumPy & Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch data\n",
    "!bash ../fetch_data.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run with KITTI\n",
    "Make sure to download the KITTI odometry dataset and set KITTI=True\n",
    "\n",
    "### Run with ad-hoc video\n",
    "Set KITTI variable to False and input variable to the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "# Handrolled\n",
    "from utils import display_mat\n",
    "from ransac import ransac\n",
    "from geometry import triangulate, fundamentalToEssential, \\\n",
    "    extract_pose, normalize, FundamentalMatrixModel, integrate_pose, calculate_projection, create_normalization_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "- KITTI: Defines if the KITTI dataset should be used (requires download from kaggle or the KITTI website)\n",
    "- input: If KITTI isn't used, this is the file to load for doing VO.\n",
    "- max_corners: Maximum keypoints returned from goodFeatureToTrack.\n",
    "- kernel_size: Size of the kernel to search for features with.\n",
    "- quality: Corner detector \"quality\".\n",
    "- ransac_minsamples: The number of samples used by RANSAC\n",
    "- ransac_max_trial: maximum iteraions of the RANSAC search.\n",
    "- ransac_residual_threshold: The residual threshold for ransac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script parameters\n",
    "KITTI = True\n",
    "KITTI_DATA_DIRECTORY = '/Users/haydenpennington/dev/data/kitti/'\n",
    "input = '../videos/test_countryroad.mp4'\n",
    "# input = 0\n",
    "im_size = (640, 480)\n",
    "\n",
    "# ORB Detector parameters\n",
    "max_corners = 1500\n",
    "kernel_size = 6\n",
    "quality = 0.001\n",
    "keypoint_size = 18\n",
    "\n",
    "# Ransac parameters\n",
    "ransac_minsamples = 8\n",
    "ransac_max_trials = 150\n",
    "ransac_residual_threshold = 0.001\n",
    "\n",
    "# Pose extratction translation scaling\n",
    "tscale = 1.0\n",
    "\n",
    "# Point cloud clustering\n",
    "n_points = 2\n",
    "dbscan_eps = tscale * 0.5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = None\n",
    "mono_folder = None\n",
    "data_folder = None\n",
    "train_image_names = None\n",
    "train_labels = None\n",
    "\n",
    "if KITTI == True:\n",
    "    seq = '00'  \n",
    "    mono_folder = 'image_2'\n",
    "    data_root = KITTI_DATA_DIRECTORY\n",
    "    data_folder = data_root + 'sequences/' + seq + '/' + mono_folder + '/'\n",
    "    train_image_names = sorted([f for f in listdir(data_folder) if isfile(join(data_folder, f))])\n",
    "    \n",
    "    with open(data_root + 'poses/' + seq + '.txt', 'r') as f:\n",
    "        train_labels = [x.split() for x in f.readlines()]\n",
    "        train_labels = np.array([[float(x) for x in y] for y in train_labels])\n",
    "        train_labels = train_labels.reshape(-1, 3, 4)\n",
    "\n",
    "## Create the ORB feature detector\n",
    "orb = cv2.ORB_create()\n",
    "## Create the feature matcher\n",
    "bf_matcher = cv2.BFMatcher(cv2.NORM_HAMMING)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_frames(T, H, W, kps1, kps2, descriptors1, descriptors2):\n",
    "    matches = bf_matcher.knnMatch(descriptors1, descriptors2, k=2)\n",
    "    matches = np.asarray(matches)\n",
    "    \n",
    "    pairs = []\n",
    "    norm_pairs = []\n",
    "    indices = []\n",
    "\n",
    "    for m,n in matches:\n",
    "        # Check Lowe's ratio\n",
    "        if m.distance < 0.75 * n.distance:\n",
    "            pt1 = np.asarray(kps1[m.queryIdx].pt)\n",
    "            pt2 = np.asarray(kps2[m.trainIdx].pt)\n",
    "            pairs.append((pt1, pt2))\n",
    "            pt1 = normalize(T, pt1)\n",
    "            pt2 = normalize(T, pt2)\n",
    "            norm_pairs.append((pt1, pt2))\n",
    "            indices.append((m.queryIdx, m.trainIdx))\n",
    "\n",
    "    pairs = np.asarray(pairs)\n",
    "    norm_pairs = np.asarray(norm_pairs)\n",
    "\n",
    "    # Filter with ransac\n",
    "    if norm_pairs[:, 0].shape[0] >= ransac_minsamples and norm_pairs[:, 1].shape[0] >= ransac_minsamples:\n",
    "        F, inliers = ransac(\n",
    "            FundamentalMatrixModel(),\n",
    "            norm_pairs,\n",
    "            min_samples=ransac_minsamples,\n",
    "            residual_threshold=ransac_residual_threshold,\n",
    "            max_trials=ransac_max_trials\n",
    "        )\n",
    "\n",
    "        return norm_pairs[inliers], pairs[inliers], F, indices\n",
    "\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(im, max_corners, quality, kernel_size, keypoint_size):\n",
    "    corners = cv2.goodFeaturesToTrack(\n",
    "        im,\n",
    "        max_corners,\n",
    "        quality,\n",
    "        kernel_size\n",
    "    )\n",
    "\n",
    "    key_points = [cv2.KeyPoint(x=x[0][0], y=x[0][1], size=keypoint_size) for x in corners]\n",
    "    return key_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'im1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 94\u001b[0m\n\u001b[1;32m     92\u001b[0m last \u001b[38;5;241m=\u001b[39m im\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m last_corners \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 94\u001b[0m     keypoints \u001b[38;5;241m=\u001b[39m extract_features(\u001b[43mim1\u001b[49m, max_corners, quality, kernel_size, keypoint_size)\n\u001b[1;32m     95\u001b[0m     last_kps, last_descriptors \u001b[38;5;241m=\u001b[39m orb\u001b[38;5;241m.\u001b[39mcompute(im, keypoints)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# last_corners = corners\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'im1' is not defined"
     ]
    }
   ],
   "source": [
    "cap = None\n",
    "if KITTI == False:\n",
    "    cap = cv2.VideoCapture(input)\n",
    "\n",
    "last = None\n",
    "last_corners = None\n",
    "last_kps = None\n",
    "last_descriptors = None\n",
    "\n",
    "R_abs = np.eye(3)\n",
    "t_abs = np.zeros(3)\n",
    "last_R = np.eye(3)\n",
    "last_t = np.zeros(3)\n",
    "t_abs_all = []\n",
    "t_abs_gt = []\n",
    "point_cloud = None\n",
    "last_proj = None\n",
    "\n",
    "i = 0\n",
    "%matplotlib widget\n",
    "while (KITTI == True and i < len(train_image_names)) or (cap is not None and cap.isOpened()):\n",
    "    t0 = time.time()\n",
    "    ret, im_original, label = None, None, None\n",
    "    if KITTI == True:\n",
    "        ret, im_original, label = True, cv2.imread(data_folder + train_image_names[i]), train_labels[i]\n",
    "    else:\n",
    "        ret, im_original = cap.read()\n",
    "\n",
    "    if ret:\n",
    "        im = im_original\n",
    "        im = cv2.resize(im_original, im_size)\n",
    "        multiplier_x = im_original.shape[1] / im.shape[1]\n",
    "        multiplier_y = im_original.shape[0] / im.shape[0]\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Create the transformation matrix for normalization\n",
    "        H, W = im.shape\n",
    "        T = create_normalization_matrix(H, W)\n",
    "\n",
    "        if last is not None:\n",
    "            im1 = im\n",
    "            im2 = last\n",
    "\n",
    "            key_points1 = extract_features(im1, max_corners, quality, kernel_size, keypoint_size)\n",
    "            kps, descriptors = orb.compute(im1, key_points1)\n",
    "\n",
    "            H, W = im1.shape\n",
    "            result = match_frames(T, H, W, kps, last_kps, descriptors, last_descriptors)\n",
    "\n",
    "            if result is not None:\n",
    "                norm_pairs, feature_pairs, F, indices = result\n",
    "\n",
    "                try:\n",
    "                    E = fundamentalToEssential(F)\n",
    "                    R, t = extract_pose(E, norm_pairs[0, 0], norm_pairs[0, 1])\n",
    "                    R_abs, t_abs = integrate_pose(R, R_abs, t, t_abs, tscale)\n",
    "                    \n",
    "                    t_abs_all.append(t_abs)\n",
    "                    \n",
    "                    if KITTI == True:\n",
    "                        t_abs_gt.append(label[:3, 3])\n",
    "                    \n",
    "                    Rt = np.eye(4)\n",
    "                    proj1 = Rt\n",
    "\n",
    "                    if last_proj is not None:\n",
    "                        proj1 = calculate_projection(R, t, last_proj)\n",
    "                        kps1 = norm_pairs[:, 0]\n",
    "                        kps2 = norm_pairs[:, 1]\n",
    "\n",
    "                        # 4d homogeneous -> 3d\n",
    "                        points4d = triangulate(proj1[:3, :4], last_proj[:3, :4], kps1, kps2, R, t)\n",
    "                        points3d = (points4d / points4d[:, 3:])[:, :3]\n",
    "\n",
    "                        if point_cloud is None:\n",
    "                            point_cloud = points3d.reshape(-1, 3)\n",
    "                        else:\n",
    "                            point_cloud = np.concatenate([point_cloud, points3d.reshape(-1, 3)]).reshape(-1, 3)\n",
    "                    \n",
    "                    last_proj = proj1\n",
    "                    \n",
    "                    for pt1, pt2 in feature_pairs:\n",
    "                        u1,v1 = int(round(pt1[0]) * multiplier_x), int(round(pt1[1]) * multiplier_y)\n",
    "                        u2,v2 = int(round(pt2[0]) * multiplier_x), int(round(pt2[1]) * multiplier_y)\n",
    "                        cv2.circle(im_original, (u1, v1), color=(0, 255, 0), radius=3)\n",
    "                        cv2.line(im_original, (u1, v1), (u2, v2), color=(255, 0, 0))\n",
    "                        cv2.circle(im_original, (u2, v2), color=(0, 0, 255), radius=3)\n",
    "\n",
    "                except ValueError as error:\n",
    "                    print('error', error)\n",
    "\n",
    "        last = im\n",
    "        if last_corners is None:\n",
    "            keypoints = extract_features(im, max_corners, quality, kernel_size, keypoint_size)\n",
    "            last_kps, last_descriptors = orb.compute(im, keypoints)\n",
    "        else:\n",
    "            # last_corners = corners\n",
    "            last_kps, last_descriptors = kps, descriptors\n",
    "\n",
    "        cv2.imshow('im1', im_original)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        if (i > 99 and i % 100 == 0) or (i > 0 and i < 11 and i % 10 == 0):\n",
    "            display_mat(cv2.cvtColor(im_original, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        t1 = time.time()\n",
    "        t_delta = (t1 - t0)\n",
    "        # print (1 / t_delta)\n",
    "        i += 1\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(4)\n",
    "if KITTI == False:\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the point cloud for viewing in open3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_abs_all = np.array(t_abs_all).reshape(-1, 3)\n",
    "if KITTI == True:\n",
    "    t_abs_gt = np.array(t_abs_gt)\n",
    "\n",
    "if point_cloud is not None:\n",
    "    \n",
    "    r = 0\n",
    "    \n",
    "    import open3d as o3d\n",
    "\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.transform([\n",
    "        [-1, 0,  0, 0],\n",
    "        [ 0, 1,  0, 0],\n",
    "        [ 0, 0, 1, 0],\n",
    "        [ 0, 0,  0, 1]\n",
    "    ])\n",
    "    pcd.points = o3d.utility.Vector3dVector(point_cloud)\n",
    "    ret = np.array(pcd.cluster_dbscan(eps=dbscan_eps, min_points=n_points))\n",
    "\n",
    "    # print(ret.shape)\n",
    "    print(point_cloud.shape)\n",
    "    \n",
    "    print(point_cloud[ret > 0].shape)\n",
    "    print(t_abs_all.shape)\n",
    "    # all_points = np.concatenate([point_cloud[ret > 0], t_abs_all, t_abs_gt])\n",
    "    all_points = np.concatenate([point_cloud[ret > -1], t_abs_all])\n",
    "    \n",
    "    pcd.points = o3d.utility.Vector3dVector(all_points)\n",
    "\n",
    "    red = [255, 0, 0]\n",
    "    green = [0, 255, 0]\n",
    "    blue = [0, 0, 255]\n",
    "    purple = [255, 0, 255]\n",
    "    orange = [255, 255, 0]\n",
    "    color_palette = [red, orange, blue, purple]\n",
    "    cluster_colors = {}\n",
    "\n",
    "    for n in set(ret):\n",
    "        cluster_colors[n] = color_palette[np.random.randint(len(color_palette))]\n",
    "\n",
    "    colors = np.ndarray(all_points.shape)\n",
    "\n",
    "    for i, color in enumerate(colors):\n",
    "        colors[i] = cluster_colors[ret[i]]\n",
    "    # colors[:point_cloud[ret>-1].shape[0]] = red\n",
    "    colors[point_cloud[ret>-1].shape[0]:point_cloud[ret>-1].shape[0]+t_abs_all.shape[0]] = green\n",
    "    # colors[point_cloud[ret>0].shape[0]+t_abs_all.shape[0]:] = blue\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "    # downpcd = pcd.voxel_down_sample(voxel_size=0.5)\n",
    "    # ret = np.asarray(point_cloud).flatten()[ret]\n",
    "\n",
    "    o3d.io.write_point_cloud(\"../pointcloud_clustered.pcd\", pcd)\n",
    "    # visualizer = o3d.JVisualizer()\n",
    "    # visualizer.add_geometry(pcd)\n",
    "    # visualizer.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the 3d trajectory of the camera\n",
    "### Red vs Green\n",
    "Red is the ground truth pose and green is the predicted pose of the camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "plt.ion()\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "# ax2 = fig.add_subplot(projection='3d')\n",
    "# pt = (t_abs_all[0, 0], t_abs_all[0, 1], t_abs_all[0, 2])\n",
    "ax.scatter(t_abs_all[:, 0], t_abs_all[:, 2], t_abs_all[:, 1], color=[(0, 1, 0)])\n",
    "\n",
    "maximum = None\n",
    "minimum = None\n",
    "\n",
    "if KITTI == True:\n",
    "    ax.scatter(t_abs_gt[:, 0], t_abs_gt[:, 2], t_abs_gt[:, 1], color=(1, 0, 0))\n",
    "    minimum = np.array(np.concatenate([t_abs_all, t_abs_gt])).min()\n",
    "    maximum = np.array(np.concatenate([t_abs_all, t_abs_gt])).max()\n",
    "else:\n",
    "    minimum = np.array(t_abs_all).min()\n",
    "    maximum = np.array(t_abs_all).max()\n",
    "    \n",
    "# ax.set_zscale(lower=minimum, upper=maxiumum, value=)\n",
    "ax.set_xlim([minimum, maximum])\n",
    "ax.set_ylim([minimum, maximum])\n",
    "ax.set_zlim([minimum, maximum])\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Z')\n",
    "ax.set_zlabel('Y')\n",
    "# plt.plot(t_abs_all[:, 0], t_abs_all[:, 1], t_abs_all[:, 2])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('pyvo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "35acd477cfcaaf878a1d13d5e7e6e4e68d98621cb7a48e0a88afaced6a1249b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
